{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c6a5940e-b024-4f70-b4f4-3ac365a64c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import  Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b6b7f863-54ee-414e-bfac-60742bec5d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.9.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#importing the necessary libraries\n",
    "import tensorflow as tf\n",
    "import gc\n",
    "from tensorflow import keras\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly import tools\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "from datetime import datetime \n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "91e711c3-8f3a-4cb5-a579-b36e14115287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import imblearn\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3dd60a25-23ab-4ad9-a24c-f6060f2c30b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset\n",
    "file = tf.keras.utils\n",
    "df = pd.read_csv('https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "06fc3bbb-7747-41c7-be5c-b58baca61f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>172786.0</td>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>172787.0</td>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>172788.0</td>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>172792.0</td>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time         V1         V2        V3        V4        V5  \\\n",
       "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
       "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
       "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
       "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
       "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
       "...          ...        ...        ...       ...       ...       ...   \n",
       "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
       "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
       "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
       "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
       "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
       "\n",
       "              V6        V7        V8        V9  ...       V21       V22  \\\n",
       "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
       "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
       "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
       "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
       "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
       "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
       "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
       "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
       "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "...       ...  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 31 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "95735a27-1162-4f28-a8eb-1c2e70eb5a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hour</th>\n",
       "      <th>Class</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Transactions</th>\n",
       "      <th>Sum</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Median</th>\n",
       "      <th>Var</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7712.43</td>\n",
       "      <td>3961</td>\n",
       "      <td>256572.87</td>\n",
       "      <td>64.774772</td>\n",
       "      <td>12.990</td>\n",
       "      <td>45615.821201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>529.00</td>\n",
       "      <td>2</td>\n",
       "      <td>529.00</td>\n",
       "      <td>264.500000</td>\n",
       "      <td>264.500</td>\n",
       "      <td>139920.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1769.69</td>\n",
       "      <td>2215</td>\n",
       "      <td>145806.76</td>\n",
       "      <td>65.826980</td>\n",
       "      <td>22.820</td>\n",
       "      <td>20053.615770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>59.0</td>\n",
       "      <td>239.93</td>\n",
       "      <td>2</td>\n",
       "      <td>298.93</td>\n",
       "      <td>149.465000</td>\n",
       "      <td>149.465</td>\n",
       "      <td>16367.832450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4002.88</td>\n",
       "      <td>1555</td>\n",
       "      <td>106989.39</td>\n",
       "      <td>68.803466</td>\n",
       "      <td>17.900</td>\n",
       "      <td>45355.430437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Hour  Class   Min      Max  Transactions        Sum        Mean   Median  \\\n",
       "0   0.0      0   0.0  7712.43          3961  256572.87   64.774772   12.990   \n",
       "1   0.0      1   0.0   529.00             2     529.00  264.500000  264.500   \n",
       "2   1.0      0   0.0  1769.69          2215  145806.76   65.826980   22.820   \n",
       "3   1.0      1  59.0   239.93             2     298.93  149.465000  149.465   \n",
       "4   2.0      0   0.0  4002.88          1555  106989.39   68.803466   17.900   \n",
       "\n",
       "             Var  \n",
       "0   45615.821201  \n",
       "1  139920.500000  \n",
       "2   20053.615770  \n",
       "3   16367.832450  \n",
       "4   45355.430437  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#time\n",
    "df['Hour'] = df['Time'].apply(lambda x: np.floor(x / 3600))\n",
    "\n",
    "tmp = df.groupby(['Hour', 'Class'])['Amount'].aggregate(['min', 'max', 'count', 'sum', 'mean', 'median', 'var']).reset_index()\n",
    "df_2 = pd.DataFrame(tmp)\n",
    "df_2.columns = ['Hour', 'Class', 'Min', 'Max', 'Transactions', 'Sum', 'Mean', 'Median', 'Var']\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5bdced0a-1e26-4019-8fa4-49445e69e2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using StandardScaler to pre process data\n",
    "cleaned_df = df.copy()\n",
    "scaler = StandardScaler() \n",
    "cleaned_df['amount_scaled'] = scaler.fit_transform(cleaned_df['Amount'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4c0d8002-4782-4e64-8ec6-24a2285e3e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking the log of the amount\n",
    "cleaned_df['amount_log'] = np.log(cleaned_df.Amount + 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e1e5b8b2-6cc5-44ae-9f0b-3c4ea804774d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a utility from sklearn to split and shuffle your dataset.\n",
    "train_df, test_df = train_test_split(cleaned_df, test_size=0.2)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2)\n",
    "\n",
    "# Form np arrays of labels and features.\n",
    "train_labels = np.array(train_df.pop('Class'))\n",
    "bool_train_labels = train_labels != 0\n",
    "val_labels = np.array(val_df.pop('Class'))\n",
    "test_labels = np.array(test_df.pop('Class'))\n",
    "\n",
    "train_features = np.array(train_df)\n",
    "val_features = np.array(val_df)\n",
    "test_features = np.array(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "39195ab5-51f2-4dce-a99c-c1056850bd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape: (182276,)\n",
      "Validation labels shape: (45569,)\n",
      "Test labels shape: (56962,)\n",
      "Training features shape: (182276, 33)\n",
      "Validation features shape: (45569, 33)\n",
      "Test features shape: (56962, 33)\n"
     ]
    }
   ],
   "source": [
    "#Normalize the input features using the sklearn StandardScaler. \n",
    "#This will set the mean to 0 and standard deviation to 1.\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "\n",
    "val_features = scaler.transform(val_features)\n",
    "test_features = scaler.transform(test_features)\n",
    "\n",
    "train_features = np.clip(train_features, -5, 5)\n",
    "val_features = np.clip(val_features, -5, 5)\n",
    "test_features = np.clip(test_features, -5, 5)\n",
    "\n",
    "\n",
    "print('Training labels shape:', train_labels.shape)\n",
    "print('Validation labels shape:', val_labels.shape)\n",
    "print('Test labels shape:', test_labels.shape)\n",
    "\n",
    "print('Training features shape:', train_features.shape)\n",
    "print('Validation features shape:', val_features.shape)\n",
    "print('Test features shape:', test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "95c088c0-120e-4d7f-8677-ffb085a54ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.653961</td>\n",
       "      <td>-0.196783</td>\n",
       "      <td>0.428614</td>\n",
       "      <td>-0.911604</td>\n",
       "      <td>-0.411716</td>\n",
       "      <td>1.351768</td>\n",
       "      <td>-1.134344</td>\n",
       "      <td>1.194327</td>\n",
       "      <td>-0.323893</td>\n",
       "      <td>-0.499698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327039</td>\n",
       "      <td>0.884643</td>\n",
       "      <td>-0.967951</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>0.121039</td>\n",
       "      <td>0.628365</td>\n",
       "      <td>-0.324151</td>\n",
       "      <td>0.618050</td>\n",
       "      <td>-0.324151</td>\n",
       "      <td>-0.592314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.301501</td>\n",
       "      <td>0.641949</td>\n",
       "      <td>0.221250</td>\n",
       "      <td>0.204569</td>\n",
       "      <td>0.487103</td>\n",
       "      <td>-0.251323</td>\n",
       "      <td>-0.796603</td>\n",
       "      <td>0.076270</td>\n",
       "      <td>-0.174927</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207073</td>\n",
       "      <td>0.571305</td>\n",
       "      <td>0.427758</td>\n",
       "      <td>0.195941</td>\n",
       "      <td>-0.052634</td>\n",
       "      <td>0.094487</td>\n",
       "      <td>-0.340127</td>\n",
       "      <td>-0.292540</td>\n",
       "      <td>-0.340127</td>\n",
       "      <td>-1.273238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.226748</td>\n",
       "      <td>-0.497547</td>\n",
       "      <td>0.698971</td>\n",
       "      <td>0.821248</td>\n",
       "      <td>0.516422</td>\n",
       "      <td>-0.234591</td>\n",
       "      <td>0.042821</td>\n",
       "      <td>0.176677</td>\n",
       "      <td>0.301212</td>\n",
       "      <td>-0.420029</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138242</td>\n",
       "      <td>0.258293</td>\n",
       "      <td>-0.498947</td>\n",
       "      <td>0.770015</td>\n",
       "      <td>-0.604447</td>\n",
       "      <td>0.119067</td>\n",
       "      <td>-0.228293</td>\n",
       "      <td>-1.203130</td>\n",
       "      <td>-0.228293</td>\n",
       "      <td>0.225027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.579302</td>\n",
       "      <td>-0.960626</td>\n",
       "      <td>1.231474</td>\n",
       "      <td>0.112534</td>\n",
       "      <td>0.938117</td>\n",
       "      <td>-0.647835</td>\n",
       "      <td>-0.115160</td>\n",
       "      <td>-0.475125</td>\n",
       "      <td>1.150578</td>\n",
       "      <td>-0.265428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.104934</td>\n",
       "      <td>0.098724</td>\n",
       "      <td>-0.049173</td>\n",
       "      <td>-0.478972</td>\n",
       "      <td>-0.267885</td>\n",
       "      <td>0.193009</td>\n",
       "      <td>-0.341296</td>\n",
       "      <td>-0.596070</td>\n",
       "      <td>-0.341296</td>\n",
       "      <td>-1.399279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.062804</td>\n",
       "      <td>-0.290046</td>\n",
       "      <td>0.865328</td>\n",
       "      <td>-0.196910</td>\n",
       "      <td>0.889209</td>\n",
       "      <td>0.291114</td>\n",
       "      <td>-0.550407</td>\n",
       "      <td>0.945384</td>\n",
       "      <td>0.054075</td>\n",
       "      <td>0.466423</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081165</td>\n",
       "      <td>-0.133194</td>\n",
       "      <td>0.068651</td>\n",
       "      <td>-0.852573</td>\n",
       "      <td>0.635046</td>\n",
       "      <td>0.541238</td>\n",
       "      <td>-0.029019</td>\n",
       "      <td>-0.064892</td>\n",
       "      <td>-0.029019</td>\n",
       "      <td>0.698957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182271</th>\n",
       "      <td>0.713314</td>\n",
       "      <td>0.961817</td>\n",
       "      <td>-0.706356</td>\n",
       "      <td>-0.085220</td>\n",
       "      <td>-0.179932</td>\n",
       "      <td>-1.142150</td>\n",
       "      <td>-0.571263</td>\n",
       "      <td>-0.720214</td>\n",
       "      <td>0.011797</td>\n",
       "      <td>-0.179941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.856219</td>\n",
       "      <td>0.781273</td>\n",
       "      <td>-1.774039</td>\n",
       "      <td>0.362798</td>\n",
       "      <td>-0.089584</td>\n",
       "      <td>-0.096100</td>\n",
       "      <td>-0.013978</td>\n",
       "      <td>0.693933</td>\n",
       "      <td>-0.013978</td>\n",
       "      <td>0.721092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182272</th>\n",
       "      <td>0.930456</td>\n",
       "      <td>-0.100676</td>\n",
       "      <td>0.459059</td>\n",
       "      <td>1.584435</td>\n",
       "      <td>3.128650</td>\n",
       "      <td>0.319387</td>\n",
       "      <td>0.834595</td>\n",
       "      <td>0.079428</td>\n",
       "      <td>-0.063500</td>\n",
       "      <td>-1.174149</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.169402</td>\n",
       "      <td>0.053215</td>\n",
       "      <td>-1.599102</td>\n",
       "      <td>0.831540</td>\n",
       "      <td>-0.515560</td>\n",
       "      <td>-0.676262</td>\n",
       "      <td>-0.323839</td>\n",
       "      <td>0.921580</td>\n",
       "      <td>-0.323839</td>\n",
       "      <td>-0.585298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182273</th>\n",
       "      <td>1.142584</td>\n",
       "      <td>1.043303</td>\n",
       "      <td>-0.026770</td>\n",
       "      <td>-0.760693</td>\n",
       "      <td>0.152062</td>\n",
       "      <td>0.110064</td>\n",
       "      <td>-0.511941</td>\n",
       "      <td>0.106005</td>\n",
       "      <td>-0.179323</td>\n",
       "      <td>0.146836</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453076</td>\n",
       "      <td>-0.510519</td>\n",
       "      <td>-0.490269</td>\n",
       "      <td>0.405643</td>\n",
       "      <td>-0.167686</td>\n",
       "      <td>-0.216344</td>\n",
       "      <td>-0.341296</td>\n",
       "      <td>1.149228</td>\n",
       "      <td>-0.341296</td>\n",
       "      <td>-1.399279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182274</th>\n",
       "      <td>1.050932</td>\n",
       "      <td>0.232528</td>\n",
       "      <td>-0.442703</td>\n",
       "      <td>-0.105994</td>\n",
       "      <td>-1.931259</td>\n",
       "      <td>-0.301293</td>\n",
       "      <td>0.179939</td>\n",
       "      <td>-0.291707</td>\n",
       "      <td>-0.008722</td>\n",
       "      <td>-1.695895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262570</td>\n",
       "      <td>0.133585</td>\n",
       "      <td>-2.359521</td>\n",
       "      <td>-0.873337</td>\n",
       "      <td>0.280812</td>\n",
       "      <td>0.401798</td>\n",
       "      <td>-0.115252</td>\n",
       "      <td>1.073345</td>\n",
       "      <td>-0.115252</td>\n",
       "      <td>0.547273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182275</th>\n",
       "      <td>-1.178899</td>\n",
       "      <td>-0.392683</td>\n",
       "      <td>0.570617</td>\n",
       "      <td>0.890599</td>\n",
       "      <td>0.484340</td>\n",
       "      <td>-0.192164</td>\n",
       "      <td>-0.467805</td>\n",
       "      <td>0.028712</td>\n",
       "      <td>0.367743</td>\n",
       "      <td>-0.730421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228022</td>\n",
       "      <td>0.656407</td>\n",
       "      <td>-1.367363</td>\n",
       "      <td>0.365680</td>\n",
       "      <td>0.032725</td>\n",
       "      <td>0.140088</td>\n",
       "      <td>-0.337438</td>\n",
       "      <td>-1.203130</td>\n",
       "      <td>-0.337438</td>\n",
       "      <td>-1.069211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182276 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6   \\\n",
       "0       0.653961 -0.196783  0.428614 -0.911604 -0.411716  1.351768 -1.134344   \n",
       "1      -0.301501  0.641949  0.221250  0.204569  0.487103 -0.251323 -0.796603   \n",
       "2      -1.226748 -0.497547  0.698971  0.821248  0.516422 -0.234591  0.042821   \n",
       "3      -0.579302 -0.960626  1.231474  0.112534  0.938117 -0.647835 -0.115160   \n",
       "4      -0.062804 -0.290046  0.865328 -0.196910  0.889209  0.291114 -0.550407   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "182271  0.713314  0.961817 -0.706356 -0.085220 -0.179932 -1.142150 -0.571263   \n",
       "182272  0.930456 -0.100676  0.459059  1.584435  3.128650  0.319387  0.834595   \n",
       "182273  1.142584  1.043303 -0.026770 -0.760693  0.152062  0.110064 -0.511941   \n",
       "182274  1.050932  0.232528 -0.442703 -0.105994 -1.931259 -0.301293  0.179939   \n",
       "182275 -1.178899 -0.392683  0.570617  0.890599  0.484340 -0.192164 -0.467805   \n",
       "\n",
       "              7         8         9   ...        23        24        25  \\\n",
       "0       1.194327 -0.323893 -0.499698  ...  0.327039  0.884643 -0.967951   \n",
       "1       0.076270 -0.174927  0.000999  ...  0.207073  0.571305  0.427758   \n",
       "2       0.176677  0.301212 -0.420029  ... -0.138242  0.258293 -0.498947   \n",
       "3      -0.475125  1.150578 -0.265428  ...  0.104934  0.098724 -0.049173   \n",
       "4       0.945384  0.054075  0.466423  ... -0.081165 -0.133194  0.068651   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "182271 -0.720214  0.011797 -0.179941  ...  0.856219  0.781273 -1.774039   \n",
       "182272  0.079428 -0.063500 -1.174149  ... -0.169402  0.053215 -1.599102   \n",
       "182273  0.106005 -0.179323  0.146836  ...  0.453076 -0.510519 -0.490269   \n",
       "182274 -0.291707 -0.008722 -1.695895  ...  0.262570  0.133585 -2.359521   \n",
       "182275  0.028712  0.367743 -0.730421  ...  0.228022  0.656407 -1.367363   \n",
       "\n",
       "              26        27        28        29        30        31        32  \n",
       "0       0.999976  0.121039  0.628365 -0.324151  0.618050 -0.324151 -0.592314  \n",
       "1       0.195941 -0.052634  0.094487 -0.340127 -0.292540 -0.340127 -1.273238  \n",
       "2       0.770015 -0.604447  0.119067 -0.228293 -1.203130 -0.228293  0.225027  \n",
       "3      -0.478972 -0.267885  0.193009 -0.341296 -0.596070 -0.341296 -1.399279  \n",
       "4      -0.852573  0.635046  0.541238 -0.029019 -0.064892 -0.029019  0.698957  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "182271  0.362798 -0.089584 -0.096100 -0.013978  0.693933 -0.013978  0.721092  \n",
       "182272  0.831540 -0.515560 -0.676262 -0.323839  0.921580 -0.323839 -0.585298  \n",
       "182273  0.405643 -0.167686 -0.216344 -0.341296  1.149228 -0.341296 -1.399279  \n",
       "182274 -0.873337  0.280812  0.401798 -0.115252  1.073345 -0.115252  0.547273  \n",
       "182275  0.365680  0.032725  0.140088 -0.337438 -1.203130 -0.337438 -1.069211  \n",
       "\n",
       "[182276 rows x 33 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e3d4478b-45a3-4aa4-a689-9ef64eb098d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 181959, 1: 317})\n",
      "Resampled dataset shape Counter({0: 181959, 1: 181959})\n"
     ]
    }
   ],
   "source": [
    "#oversampling on training data\n",
    "print('Original dataset shape %s' % Counter(train_labels))\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_ros, y_train_ros = ros.fit_resample(train_df,train_labels)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_train_ros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b2ed6dc5-e52b-40b1-b9c1-b5ae56ce5862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 56871, 1: 91})\n",
      "Resampled dataset shape Counter({0: 56871, 1: 56871})\n"
     ]
    }
   ],
   "source": [
    "#oversampling on testing data\n",
    "print('Original dataset shape %s' % Counter(test_labels))\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_test_ros, y_test_ros = ros.fit_resample(test_df,test_labels)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_test_ros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5f2f00af-1cd1-433c-800c-19ab136a62d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 45485, 1: 84})\n",
      "Resampled dataset shape Counter({0: 45485, 1: 45485})\n"
     ]
    }
   ],
   "source": [
    "#oversampling on testing data\n",
    "print('Original dataset shape %s' % Counter(val_labels))\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_val_ros, y_val_ros = ros.fit_resample(val_df, val_labels)\n",
    "\n",
    "print('Resampled dataset shape %s' % Counter(y_val_ros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "94caef48-6784-4662-8128-5b55d828df55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training outputs\n",
    "Y_train_ros = np.zeros([len(y_train_ros),2])\n",
    "for y in range(len(y_train_ros)):\n",
    "    if y_train_ros[y]==1:\n",
    "        Y_train_ros[y,1] = 1\n",
    "    else:\n",
    "        Y_train_ros[y,0] = 1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "19c6924c-7d78-422e-bfd2-d290ec3a22d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_ros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ab3eb3b0-664d-42c5-9fae-1c83c13c565e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing the data for training\n",
    "Y_val_ros = np.zeros([len(y_val_ros),2])\n",
    "\n",
    "for y in range(len(y_val_ros)):\n",
    "    if y_val_ros[y]==1:\n",
    "        Y_val_ros[y,1] = 1\n",
    "    else:\n",
    "        Y_val_ros[y,0] = 1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6f63b5d7-3251-4846-8ae6-e0550a05801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing data for validation\n",
    "Y_test_ros = np.zeros([len(y_test_ros),2])\n",
    "for y in range(len(y_test_ros)):\n",
    "    if y_test_ros[y]==1:\n",
    "        Y_test_ros[y,1] = 1\n",
    "    else:\n",
    "        Y_test_ros[y,0] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1568ea71-c73d-418c-8b47-582a6a6bc295",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Creation of the model layers\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train_ros.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(2, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7327a58c-6bbd-461d-b0ae-398297730060",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8468387a-768a-4fdc-b5f5-62057531c49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2297cdef-5c29-493d-b2dc-ec9d12cdc732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "11373/11373 [==============================] - 33s 3ms/step - loss: 0.6932 - accuracy: 0.5006 - val_loss: 0.8798 - val_accuracy: 0.4943\n",
      "Epoch 2/25\n",
      "11373/11373 [==============================] - 33s 3ms/step - loss: 0.6932 - accuracy: 0.5009 - val_loss: 0.7202 - val_accuracy: 0.4944\n",
      "Epoch 3/25\n",
      "11373/11373 [==============================] - 37s 3ms/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.6903 - val_accuracy: 0.5059\n",
      "Epoch 4/25\n",
      "11373/11373 [==============================] - 35s 3ms/step - loss: 0.6932 - accuracy: 0.4985 - val_loss: 0.6908 - val_accuracy: 0.5002\n",
      "Epoch 5/25\n",
      "11373/11373 [==============================] - 35s 3ms/step - loss: 0.6929 - accuracy: 0.5032 - val_loss: 0.7972 - val_accuracy: 0.4948\n",
      "Epoch 6/25\n",
      "11373/11373 [==============================] - 34s 3ms/step - loss: 0.6932 - accuracy: 0.5012 - val_loss: 0.7872 - val_accuracy: 0.4943\n",
      "Epoch 7/25\n",
      "11373/11373 [==============================] - 35s 3ms/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.7595 - val_accuracy: 0.4941\n",
      "Epoch 8/25\n",
      "11373/11373 [==============================] - 33s 3ms/step - loss: 0.6932 - accuracy: 0.5001 - val_loss: 0.9500 - val_accuracy: 0.4941\n",
      "Epoch 9/25\n",
      "11373/11373 [==============================] - 34s 3ms/step - loss: 0.6932 - accuracy: 0.4980 - val_loss: 0.7086 - val_accuracy: 0.4940\n",
      "Epoch 10/25\n",
      "11373/11373 [==============================] - 40s 3ms/step - loss: 0.6932 - accuracy: 0.5012 - val_loss: 0.6931 - val_accuracy: 0.5001\n",
      "Epoch 11/25\n",
      "11373/11373 [==============================] - 43s 4ms/step - loss: 0.6932 - accuracy: 0.5001 - val_loss: 0.6938 - val_accuracy: 0.4940\n",
      "Epoch 12/25\n",
      "11373/11373 [==============================] - 41s 4ms/step - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 13/25\n",
      "11373/11373 [==============================] - 41s 4ms/step - loss: 0.6932 - accuracy: 0.5001 - val_loss: 0.6935 - val_accuracy: 0.5001\n",
      "Epoch 14/25\n",
      "11373/11373 [==============================] - 41s 4ms/step - loss: 0.6932 - accuracy: 0.4990 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 15/25\n",
      "11373/11373 [==============================] - 42s 4ms/step - loss: 0.6932 - accuracy: 0.5002 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 16/25\n",
      "11373/11373 [==============================] - 41s 4ms/step - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 17/25\n",
      "11373/11373 [==============================] - 38s 3ms/step - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6949 - val_accuracy: 0.5000\n",
      "Epoch 18/25\n",
      "11373/11373 [==============================] - 36s 3ms/step - loss: 0.6932 - accuracy: 0.5021 - val_loss: 0.6933 - val_accuracy: 0.5000\n",
      "Epoch 19/25\n",
      "11373/11373 [==============================] - 38s 3ms/step - loss: 0.6932 - accuracy: 0.4992 - val_loss: 0.6929 - val_accuracy: 0.5000\n",
      "Epoch 20/25\n",
      "11373/11373 [==============================] - 37s 3ms/step - loss: 0.6932 - accuracy: 0.5006 - val_loss: 0.6942 - val_accuracy: 0.5000\n",
      "Epoch 21/25\n",
      "11373/11373 [==============================] - 36s 3ms/step - loss: 0.6932 - accuracy: 0.4988 - val_loss: 0.6950 - val_accuracy: 0.4939\n",
      "Epoch 22/25\n",
      "11373/11373 [==============================] - 35s 3ms/step - loss: 0.6932 - accuracy: 0.5003 - val_loss: 0.7045 - val_accuracy: 0.4941\n",
      "Epoch 23/25\n",
      "11373/11373 [==============================] - 36s 3ms/step - loss: 0.6932 - accuracy: 0.4995 - val_loss: 0.6900 - val_accuracy: 0.5002\n",
      "Epoch 24/25\n",
      "11373/11373 [==============================] - 35s 3ms/step - loss: 0.6931 - accuracy: 0.5021 - val_loss: 0.8520 - val_accuracy: 0.4942\n",
      "Epoch 25/25\n",
      "11373/11373 [==============================] - 35s 3ms/step - loss: 0.6932 - accuracy: 0.5000 - val_loss: 1.2307 - val_accuracy: 0.4942\n",
      "INFO:tensorflow:Assets written to: Fraud transaction detection\\assets\n"
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "history = model.fit(X_train_ros, Y_train_ros, batch_size=32, epochs=epochs, validation_data=(X_val_ros,Y_val_ros))\n",
    "model.save(\"Fraud transaction detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a2d15481-72d1-4770-9919-9b040d4abc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3555/3555 [==============================] - 4s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "#predicting testing data\n",
    "preds = model.predict(X_test_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "24213d7e-1334-433b-9aac-24705fcacf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifying the class\n",
    "preds = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4edc9d86-69a8-4db5-8ef1-07d35f7a9872",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy of the testing data\n",
    "accuracy = accuracy_score(y_test_ros, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "47e5b7c7-7280-4ce2-b811-c8cd6c92c078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.500395632220288"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e1e489ea-d902-4206-80ac-82f2918c7ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00     56871\n",
      "           1       0.50      1.00      0.67     56871\n",
      "\n",
      "    accuracy                           0.50    113742\n",
      "   macro avg       0.75      0.50      0.33    113742\n",
      "weighted avg       0.75      0.50      0.33    113742\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the classification report\n",
    "report = classification_report(y_test_ros, preds)\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5adc59b2-57b2-43e7-8efc-8d4e9c4ee53f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "cm = pd.crosstab(y_test_ros, preds, rownames=['Actual'], colnames=['Predicted'])\n",
    "fig, (ax1) = plt.subplots(ncols=1, figsize=(5,5))\n",
    "sns.heatmap(cm, \n",
    "            xticklabels=['Not Fraud', 'Fraud'],\n",
    "            yticklabels=['Not Fraud', 'Fraud'],\n",
    "            annot=True,ax=ax1,\n",
    "            linewidths=.2,linecolor=\"Darkblue\", cmap=\"Blues\")\n",
    "plt.title('Confusion Matrix', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "062a6caa-cf4e-43b5-9d17-8db475da8167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC: 0.500395632220288\n"
     ]
    }
   ],
   "source": [
    "# Calculate the AUC-ROC\n",
    "auc_roc = roc_auc_score(y_test_ros,preds)\n",
    "\n",
    "print(\"AUC-ROC:\", auc_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5a5b3a-b9e9-4836-9271-2f8a1da80ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbd1978-f0b8-4798-a8c1-fcd74df92b23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
